{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv('/content/your_dataset.csv')\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataset to verify it's loaded correctly\n",
        "print(df.head())\n",
        "\n",
        "# Select features and target variable\n",
        "# Assuming 'loan_status' is the target column\n",
        "# Ignoring the 'Unnamed: 0' column as it's likely an index\n",
        "features = ['Principal', 'terms', 'effective_date', 'due_date', 'age', 'education', 'Gender']\n",
        "target = 'loan_status'\n",
        "\n",
        "# Create feature and target DataFrames\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Display the first few rows of features and target to confirm\n",
        "print(X.head())\n",
        "print(y.head())\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "print(f'Training features shape: {X_train.shape}')\n",
        "print(f'Testing features shape: {X_test.shape}')\n",
        "print(f'Training target shape: {y_train.shape}')\n",
        "print(f'Testing target shape: {y_test.shape}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LnEGIoak9zr",
        "outputId": "a6d276bc-8039-4a21-c2d2-69eb5118b3c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0.1  Unnamed: 0 loan_status  Principal  terms effective_date  \\\n",
            "0             0           0     PAIDOFF       1000     30       9/8/2016   \n",
            "1             2           2     PAIDOFF       1000     30       9/8/2016   \n",
            "2             3           3     PAIDOFF       1000     15       9/8/2016   \n",
            "3             4           4     PAIDOFF       1000     30       9/9/2016   \n",
            "4             6           6     PAIDOFF       1000     30       9/9/2016   \n",
            "\n",
            "    due_date  age             education  Gender  \n",
            "0  10/7/2016   45  High School or Below    male  \n",
            "1  10/7/2016   33              Bechalor  female  \n",
            "2  9/22/2016   27               college    male  \n",
            "3  10/8/2016   28               college  female  \n",
            "4  10/8/2016   29               college    male  \n",
            "   Principal  terms effective_date   due_date  age             education  \\\n",
            "0       1000     30       9/8/2016  10/7/2016   45  High School or Below   \n",
            "1       1000     30       9/8/2016  10/7/2016   33              Bechalor   \n",
            "2       1000     15       9/8/2016  9/22/2016   27               college   \n",
            "3       1000     30       9/9/2016  10/8/2016   28               college   \n",
            "4       1000     30       9/9/2016  10/8/2016   29               college   \n",
            "\n",
            "   Gender  \n",
            "0    male  \n",
            "1  female  \n",
            "2    male  \n",
            "3  female  \n",
            "4    male  \n",
            "0    PAIDOFF\n",
            "1    PAIDOFF\n",
            "2    PAIDOFF\n",
            "3    PAIDOFF\n",
            "4    PAIDOFF\n",
            "Name: loan_status, dtype: object\n",
            "Training features shape: (276, 7)\n",
            "Testing features shape: (70, 7)\n",
            "Training target shape: (276,)\n",
            "Testing target shape: (70,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"effective_date\", \"due_date\"])\n",
        "\n",
        "# Convert categorical features using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=[\"education\", \"Gender\"], drop_first=True)\n",
        "\n",
        "# Define the feature set X and the target variable y\n",
        "X = df.drop(columns=[\"loan_status\"])\n",
        "y = df[\"loan_status\"].apply(lambda x: 1 if x == 'PAIDOFF' else 0)  # Convert target to binary\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"Mean Squared Error: {mse:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M545Ouft5K_b",
        "outputId": "41e0f5eb-ce75-4fca-deaf-e02f1f82a1dd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.179\n",
            "R² Score: -0.120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary with the evaluation metrics\n",
        "metrics = {\n",
        "    'Model': ['Linear Regression'],\n",
        "    'Mean Squared Error': [mse],\n",
        "    'R² Score': [r2]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Display the table\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaID_boY5U4h",
        "outputId": "6240677b-e725-40e1-9cde-0686a156efec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Model  Mean Squared Error  R² Score\n",
            "0  Linear Regression            0.179133  -0.11958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize and train the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "f1_knn = f1_score(y_test, y_pred_knn)\n",
        "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "class_report_knn = classification_report(y_test, y_pred_knn)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"KNN Accuracy: {accuracy_knn:.3f}\")\n",
        "print(f\"KNN F1 Score: {f1_knn:.3f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_knn)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_knn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMOfdhN05e_p",
        "outputId": "6309db65-e134-4c0d-fa05-a6561a8e2505"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.714\n",
            "KNN F1 Score: 0.833\n",
            "Confusion Matrix:\n",
            "[[ 0 14]\n",
            " [ 6 50]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.78      0.89      0.83        56\n",
            "\n",
            "    accuracy                           0.71        70\n",
            "   macro avg       0.39      0.45      0.42        70\n",
            "weighted avg       0.62      0.71      0.67        70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize and train the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "class_report_dt = classification_report(y_test, y_pred_dt)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.3f}\")\n",
        "print(f\"Decision Tree F1 Score: {f1_dt:.3f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmzFLeRJ5sA1",
        "outputId": "8836556f-ac14-457f-b894-33fcb932f300"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.643\n",
            "Decision Tree F1 Score: 0.762\n",
            "Confusion Matrix:\n",
            "[[ 5  9]\n",
            " [16 40]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.36      0.29        14\n",
            "           1       0.82      0.71      0.76        56\n",
            "\n",
            "    accuracy                           0.64        70\n",
            "   macro avg       0.53      0.54      0.52        70\n",
            "weighted avg       0.70      0.64      0.67        70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
        "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
        "class_report_logreg = classification_report(y_test, y_pred_logreg)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logreg:.3f}\")\n",
        "print(f\"Logistic Regression F1 Score: {f1_logreg:.3f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_logreg)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_logreg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOIkdIRx50nY",
        "outputId": "25fda429-9f12-41a5-f62a-fdf8ebd272cf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.800\n",
            "Logistic Regression F1 Score: 0.889\n",
            "Confusion Matrix:\n",
            "[[ 0 14]\n",
            " [ 0 56]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.80      1.00      0.89        56\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.40      0.50      0.44        70\n",
            "weighted avg       0.64      0.80      0.71        70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "class_report_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.3f}\")\n",
        "print(f\"SVM F1 Score: {f1_svm:.3f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcVXKQ756Aee",
        "outputId": "0f6d8207-0e3b-4fb0-8277-bd9a39bdffe0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.800\n",
            "SVM F1 Score: 0.889\n",
            "Confusion Matrix:\n",
            "[[ 0 14]\n",
            " [ 0 56]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.80      1.00      0.89        56\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.40      0.50      0.44        70\n",
            "weighted avg       0.64      0.80      0.71        70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary with the evaluation metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['Accuracy', 'F1 Score'],\n",
        "    'Value': [accuracy_svm, f1_svm]\n",
        "}\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Display the metrics table\n",
        "print(\"Final Classification Report for SVM Model\")\n",
        "print(metrics_df)\n",
        "\n",
        "# Display the confusion matrix and classification report\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix_svm)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbKVaxvS6P5c",
        "outputId": "8dc0b51f-7c67-4bef-f74f-e5b8c546b95f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Classification Report for SVM Model\n",
            "     Metric     Value\n",
            "0  Accuracy  0.800000\n",
            "1  F1 Score  0.888889\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 0 14]\n",
            " [ 0 56]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.80      1.00      0.89        56\n",
            "\n",
            "    accuracy                           0.80        70\n",
            "   macro avg       0.40      0.50      0.44        70\n",
            "weighted avg       0.64      0.80      0.71        70\n",
            "\n"
          ]
        }
      ]
    }
  ]
}